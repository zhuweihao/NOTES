# CDC概述

CDC 的全称是 Change Data Capture ，在广义的概念上，只要是能捕获数据变更的技术，我们都 可以称之为 CDC 。目前通常描述的 CDC 技术主要面向数据库的变更，是一种用于捕获数据库中 数据变更的技术。CDC 技术的应用场景非常广泛： 

- 数据迁移：常用于数据库备份、容灾等； 
- 数据分发：将一个数据源分发给多个下游，常用于业务解耦、微服务； 
- 数据集成：将分散异构的数据源集成到数据仓库中，消除数据孤岛，便于后续的分析。

目前业界主流的 CDC 实现机制可以分为两种：

- 基于查询的CDC
  - 离线调度查询作业，批处理。依赖表中的更新时间字段，每次执行查询去获取表中最新的数据；
  -  无法捕获删除事件，从而无法保证数据一致性；
  - 无法保障实时性，基于离线调度存在天然的延迟。
- 基于日志的CDC
  - 实时消费日志，流处理。
  - 保障数据一致性，因为binlog文件包含了所有历史变更明细；
  - 保障实时性，因为类似binlog的日志文件是可以流式消费的，提供的是实时数据。

# Flink CDC

![image-20220120090442275](https://s2.loli.net/2022/01/20/QYbZMeN93gfP7xD.png)

Flink 有两个基础概念：Dynamic Table 和 Changelog Stream

- Dynamic Table 就是 Flink SQL 定义的动态表，动态表和流的概念是对等的。流可以转换成动态表，动态表也可以转换成流。
- 在 Flink SQL 中，数据在从一个算子流向另外一个算子时都是以 Changelog Stream 的形式， 任意时刻的 Changelog Stream 可以翻译为一个表，也可以翻译为一个流

---



![image-20220120090930303](https://s2.loli.net/2022/01/20/AxjiMnqNkwY1LbJ.png)

传统的基于 CDC 的 ETL 分析中，数据采集工具是必须的，国外用户常用 Debezium，国内用户常用阿里开源的 Canal，采集工具负责采集数据库的增量数据，一些采集工具也支持全量数据同步。 采集到的数据一般输出到消息中间件如Kafka，然后Flink计算引擎再去消费数据并写入到目的端， 目的端可以是各种数据库、数据仓库、数据湖和消息队列。

![image-20220120091058025](https://s2.loli.net/2022/01/20/YpZHdm5DGejQz8c.png)

在使用了Flink CDC之后，除了组件更少，维护更方便外，另一个优势是通过 Flink SQL 极大地降低了用户使用门槛，通过 Flink SQL 原生支持的 Changelog 机制，可以让 CDC 数据的加工变得非常简单，用户可以通过 SQL 便能实现数据库全量和增量数据的清洗、打宽、聚合等操作。 此外， Flink DataStream API 支持用户编写代码实现自定义逻辑，给用户提供了深度定制业务的自由度。

---

- 全量 + 增量读取的过程需要保证所有数据的一致性，因此需要通过全局锁保证，全局锁容易导致数据库hang住，表锁会锁住加锁的表，对在线业务造成影响，且 DBA 一般不给锁权限。
-  不支持水平扩展，因为 Flink CDC 底层是基于 Debezium，其架构是单节点，所以 Flink CDC 的数据源只支持单并发。在全量阶段读取阶段，如果表非常大 ，读取时间在小时甚至天级别，用户无法通过增加资源去提升作业速度。 
- 全量读取阶段不支持 checkpoint：CDC 读取分为两个阶段，全量读取和增量读取，1.0版本全量读取阶段是不支持 checkpoint 的，因此会存在一个问题：当我们同步全量数据时，假设需要 5 个小时，当我们同步了 4 小时的时候作业失败，这时候就需要重新开始，再读取 5 个小时

 针对这些问题，Flink CDC 社区提出了“增量快照读取算法”，同时实现了无锁读取、并行读取、 断点续传等能力，一并解决了上述痛点。

Flink CDC 2.0 正式发布，核心改进和提升包括：

- 并发读取，全量数据的读取性能可以水平扩展； 
- 全程无锁，不对线上业务产生锁的风险； 
- 断点续传，支持全量阶段的 checkpoint。

![image-20220120094509505](https://s2.loli.net/2022/01/20/VWP4NTaShUOxopr.png)

Flink CDC 技术的核心是支持将表中的全量数据和增量数据做实时一致性的同步与加工，让用户可以方便地获每张表的实时一致性快照。比如一张表中有历史的全量业务数据，也有增量的业务数据 在源源不断写入，更新。Flink CDC 会实时抓取增量的更新记录，实时提供与数据库中一致性的快照，如果是更新记录，会更新已有数据。如果是插入记录，则会追加到已有数据，整个过程中， Flink CDC 提供了一致性保障，即不重不丢。

# FlinkCDC实时数据入湖入仓

-  依赖离线的定时合并，只能做到小时级产出，延时还是较大； 
- 全量和增量是割裂的两条链路； 
-  整个架构链路长，需要维护的组件比较多，该架构的全量链路需要维护 DataX 或 Sqoop 组件， 增量链路要维护 Canal 和 Kafka 组件，同时还要维护全量和增量的定时合并链路。

<img src="https://s2.loli.net/2022/01/20/dnoA1pKER8acFG2.png" alt="image-20220120100032696" style="zoom: 67%;" />

对于传统数据入仓架构存在的问题，Flink CDC 的出现为数据入湖架构提供了一些新思路。借助 Fl ink CDC 技术的全增量一体化实时同步能力，结合数据湖提供的更新能力，整个架构变得非常简洁。 我们可以直接使用 Flink CDC 读取 MySQL 的全量和增量数据，并直接写入和更新到 Hudi 中。 

这种简洁的架构有着明显的优势。

- 不会影响业务稳定性。
- 提供分钟级产出，满足近实时业务的需求。
- 全量和增量的链路完成了统一，实现了一体化同步。
- 该架构的链路更 短，需要维护的组件更少

![image-20220120100233482](https://s2.loli.net/2022/01/20/1FRBJSqPM9uc3Yk.png)

Flink CDC 的核心特性可以分成四个部分：

- 一是通过增量快照读取算法，实现了无锁读取，并发读取，断点续传等功能。
- 二是设计上对入湖友好，提升了 CDC 数据入湖的稳定性。
- 三是支持异构数 据源的融合，能方便地做 Streaming ETL 的加工。
- 四是支持分库分表合并入湖。

<img src="https://s2.loli.net/2022/01/20/bcSW1YFhfpkR9ot.png" alt="image-20220120095053905" style="zoom:50%;" />

简单来说，增量快照读取算法的核心思路就是在全量读取阶段把表分成一个个 chunk 进行并发读 取，在进入增量阶段后只需要一个 task 进行单并发读取 binlog 日志，在全量和增量自动切换时， 通过无锁算法保障一致性。这种设计在提高读取效率的同时，进一步节约了资源。

<img src="C:\Users\ZWH\AppData\Roaming\Typora\typora-user-images\image-20220120095252837.png" alt="image-20220120095252837" style="zoom: 67%;" />

Flink CDC 是一个流式入湖友好的框架。在早期版本的 Flink CDC 设计中，没有考虑数据湖场景， 全量阶段不支持 Checkpoint，全量数据会在一个 Checkpoint 中处理，这对依靠 Checkpoint 提 交数据的数据湖很不友好。Flink CDC 2.0 设计之初考虑了数据湖场景，是一种流式入湖友好的设 计。设计上将全量数据进行分片，Flink CDC 可以将 checkpoint 粒度从表粒度优化到 chunk 粒度，大大减少了数据湖写入时的 Buffer 使用，对数据湖写入更加友好。

![image-20220120095401131](https://s2.loli.net/2022/01/20/Z8WlQLPURXFVt1n.png)

Flink CDC 区别于其他数据集成框架的一个核心点，就是在于Flink提供的流批一体计算能力。这使得Flink CDC成为了一个完整的ETL工具，不仅仅拥有出色的 E和 L 的能力，还拥有强大的Transformation能力。因此我们可以轻松实现基于异构数据源的数据湖构建。

![image-20220120095543519](https://s2.loli.net/2022/01/20/mFPDg1AsKjrizVb.png)

在 OLTP 系统中，为了解决单表数据量大的问题，通常采用分库分表的方式将单个大表进行拆分以 提高系统的吞吐量。但是为了方便数据分析，通常需要将分库分表拆分出的表在同步到数据仓库、 数据湖时，再合并成一个大表，Flink CDC 可以轻松完成这个任务。





数据仓库  cdc在生态中的作用

无锁算法

flinkcdc2.0生态问题 ，偏向应用



# 基于Flink CDC 2.0的实时数据接入技术的研究与应用
