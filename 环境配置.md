# CentOS虚拟机安装

1. 官网下载VMware，百度密钥即可解锁
2. 官网下载CentOS镜像文件，下载速度较慢，建议挂网或从国内的镜像网站下载
3. VMware参照引导创建虚拟机即可，注意：
   - 虚拟机内存建议最小3G，否则影响使用体验
   - 网络类型选择桥接网络
   - 磁盘大小建议资源允许范围内越大越好，以防后期出现问题
4. 设置虚拟机使用准备好的ios镜像文件，然后开机即可开始系统安装<img src="https://s2.loli.net/2022/06/09/KUO1Ftcd7sZaHoJ.png" alt="image-20220609145216094" style="zoom:80%;" />
5. 对上图中所有内容进行配置，注意分区设置选择自定义分区<img src="https://s2.loli.net/2022/06/09/vUcAN5EtohiyOMQ.png" alt="image-20220609145458323" style="zoom:80%;" />

防火墙设置

```
#查看防火墙状态
systemctl status firewalld
#关闭防火墙
systemctl stop firewalld
#禁用防火墙
systemctl disable firewalld
```

如果此时ping主机不能通过需要对主机防火墙进行设置，如下

![image-20220614140633341](https://s2.loli.net/2022/06/14/RkAMpgFNQeyG95z.png)

禁用SELINUX

```
vi /etc/selinux/config
```

<img src="https://s2.loli.net/2022/06/13/bd7yBZvhmrkQOnE.png" alt="image-20220613161355284" style="zoom:67%;" />

图中为修改后的效果，应该修改的地方为SELINUX=后面的内容，将其改为disable

SSH配置：

检查ssh client和ssh server是否安装

```
rpm -qa | grep ssh
```

![image-20220613161948625](https://s2.loli.net/2022/06/13/xad7IO8jCl4oQcy.png)

如果没有使用如下命令进行安装

```
sudo yum install openssh-clients
sudo yum install openssh-server
```

测试SSH是否可用

```
ssh localhost
```

此时会有如下提示(SSH首次登陆提示)，输入 yes ，然后按提示输入密码 

![image-20220613162403564](https://s2.loli.net/2022/06/13/yEouaGJ6iv3YkWs.png)

首先输入 exit 退出刚才的 ssh，然后利用 ssh-keygen 生成密钥，并将密钥加入到授权中：

```
exit                           # 退出刚才的 ssh localhost
cd ~/.ssh/                     # 若没有该目录，请先执行一次ssh localhost
ssh-keygen -t rsa              # 会有提示，都按回车就可以
cat id_rsa.pub >> authorized_keys  # 加入授权
chmod 600 ./authorized_keys    # 修改文件权限
```

<img src="https://s2.loli.net/2022/06/13/jyHWx3AKB5E9e4b.png" alt="image-20220613162617165" style="zoom:67%;" />

此时再用 ssh localhost 命令，无需输入密码就可以直接登陆了，如下图所示

![image-20220613162753911](https://s2.loli.net/2022/06/13/bu3O6TIASRwahHf.png)

在 Linux 系统中，~ 代表的是用户的主文件夹，即 “/home/用户名” 这个目录，例如我的用户名为zhuweihao，则~就代表/home/zhuweihao

# CentOS 8安装mysql 8

##### 安装

方式一：

```
sudo dnf install @mysql
```

这种方式未经过成功的实践，CentOS 8上提供有MySQL 8，但是该种方法不太稳定

<img src="https://s2.loli.net/2022/06/13/DAP7rW3KBX8Q5zs.png" alt="image-20220609163048836" style="zoom:80%;" />

会产生报错

```
错误：Failed to download metadata for repo 'appstream': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried
```

方式二：

<img src="https://s2.loli.net/2022/06/09/WQV4IpA6XbhDUNJ.png" alt="image-20220609164321143" style="zoom: 67%;" />

官网下载合适的离线包，解压

依次执行下列命令进行安装

```
sudo rpm -ivh mysql-community-common-8.0.29-1.el8.x86_64.rpm
sudo rpm -ivh mysql-community-client-plugins-8.0.29-1.el8.x86_64.rpm
sudo rpm -ivh mysql-community-libs-8.0.29-1.el8.x86_64.rpm
sudo rpm -ivh mysql-community-client-8.0.29-1.el8.x86_64.rpm
sudo rpm -ivh mysql-community-icu-data-files-8.0.29-1.el8.x86_64.rpm
sudo rpm -ivh mysql-community-server-8.0.29-1.el8.x86_64.rpm
```

##### 配置

安装完成后，启动 MySQL 服务，并设置开机自启

```
sudo systemctl enable --now mysqld
```

检查MySQL状态

```
sudo systemctl status mysqld
```

获取MySQL初始密码

```
cat /var/log/mysqld.log | grep password
```

登录MySQL数据库

```
mysql -u root -p
```

接下来需要修改密码，这里需要注意如果直接使用下面的方法修改密码会报错：

```
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456';
```

```
ERROR 1819 (HY000): Your password does not satisfy the current policy requirements
```

使用如下命令命令可以查看默认的密码规则

```
SHOW VARIABLES LIKE 'validate_password%';
```

![image-20220609170015811](https://s2.loli.net/2022/06/09/4mgVkZTURAwqON9.png)

默认的密码规则如上图所示，故需要先修改一个符合条件密码，然后再利用下列命令对密码规则进行修改

```
set global validate_password.policy=LOW;
set global validate_password.length=5;
```

需要注意MySQL 5与MySQL 8中密码规则的系统变量名不同，若使用MySQL 5则应使用如下命令

```
set global validate_password_policy=LOW;
set global validate_password_length=5;
```

修改后的密码规则如下图所示,

![image-20220609165945514](https://s2.loli.net/2022/06/09/MYaiU5AulBVC7df.png)

现在修改密码后就可以使用新密码进行登录了

# JDK17配置

如果有图形化界面可直接到ORACLE官网下载相应版本JDK后进行后续配置，或者采用如下方法

```
cd ~/opt
wget https://download.oracle.com/java/17/latest/jdk-17_linux-x64_bin.tar.gz
```

解压压缩包，删除压缩包

```
tar -zxvf jdk-17_linux-x64_bin.tar.gz 
rm -rf jdk-17_linux-x64_bin.tar.gz 
```

配置环境变量：

方法一：

直接编辑profile文件，在文件最下方添加相关设置，注意jdk版本不同需进行相关修改

```
vim /etc/profile
export JAVA_HOME=~/opt/jdk-17.0.3.1
export PATH=$PATH:$JAVA_HOME/bin;
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar;
```

方法二：

在/etc/profile.d 目录中存放的是一些应用程序所需的启动脚本，其中包括了颜色、语言、less、vim及which等命令的一些附加设置。

这些脚本文件之所以能够 被自动执行，是因为在/etc/profile 中使用一个for循环语句来调用这些脚本。而这些脚本文件是用来设置一些变量和运行一些初始化过程的。
作为额外的环境变量，使用方法二可以避免污染初始环境变量

```
cd /etc/profile.d
vim java.sh
export JAVA_HOME=~/opt/jdk-17.0.3.1
export PATH=$PATH:$JAVA_HOME/bin;
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar;
#保存后
chmod 755 /etc/profile.d/java.sh
```

最后重载环境变量

```
source /etc/profile
```



# Hadoop安装与配置

从镜像网站下载相应版本hadoop

[Index of /apache/hadoop/common (cnnic.cn)](https://mirrors.cnnic.cn/apache/hadoop/common/)

下载后进行解压

配置环境变量，方法与JDK配置时相似

```
cd /etc/profile.d
sudo vim hadoop.sh
#将下列代码插入后保存
export HADOOP_HOME=~/opt/hadoop-3.3.3
export PATH=$HADOOP_HOME/bin:$PATH
#重新加载环境变量
source /etc/profile
```

![image-20220614141604846](https://s2.loli.net/2022/06/14/sxv4YluLybZgJa5.png)

验证hadoop是否配置成功

```
hadoop version
```

![image-20220614141825278](https://s2.loli.net/2022/06/14/wlZVLUhMAFi1WGu.png)

伪分布设置

配置环境变量

```
vim ~/.bashrc
#将下列内容添加进去
export HADOOP_HOME=~/opt/hadoop-3.3.3
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

source ~/.bashrc
```



Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。

```
cd ~/opt/hadoop-3.3.3/etc/hadoop
ll
```

![image-20220614143246760](https://s2.loli.net/2022/06/14/tnCqo5TDd7QiZ1g.png)

接下来要配置的文件均使用了下列命令进行权限的管理，就不全部列出了

```
chmod 777 core-site.xml
```



- core-site.xml

```
vim core-site.xml
#添加如下配置
<configuration>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/home/zhuweihao/opt/hadoop-3.3.3/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://localhost:9000</value>
        </property>
</configuration>
```

- hdfs-site.xml

```
vim hdfs-site.xml
#添加如下配置
<configuration>
        <property>
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>/home/zhuweihao/opt/hadoop-3.3.3/tmp/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>/home/zhuweihao/opt/hadoop-3.3.3/tmp/dfs/data</value>
        </property>
        <property>
                <name>dfs.secondary.http.address</name>
                <!--这里是你自己的ip，端口默认-->
                <value>dfs://localhost:50070</value>
        </property>
</configuration>
```

- mapred-site.xml

```
vim mapred-site.xml
#添加如下配置
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
        <property>
                <name>mapred.job.tracker.http.address</name>
                <value>0.0.0.0:50030</value>
        </property>

        <property>
                <name>mapred.task.tracker.http.address</name>
                <value>0.0.0.0:50060</value>
        </property>
        <property>
                <name>mapreduce.admin.user.env</name>
                <value>HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME</value>
        </property>
        <property>
                <name>yarn.app.mapreduce.am.env</name>
                <value>HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME</value>
        </property>
</configuration>
```

- yarn-site.xml

```
vim yarn-site.xml
#添加如下配置
<configuration>
        <property>
                 <name>yarn.resourcemanager.hostname</name>
                <!-- 自己的ip端口默认 -->
                <value>hdfs://localhost:9000</value>
        </property>
        <!-- reducer获取数据的方式 -->
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
<!-- Site specific YARN configuration properties -->

</configuration>
```

- hadoop-env.sh

```
vim hadoop-env.sh
#添加如下配置
export JAVA_HOME=~/opt/jdk/jdk-11.0.15.1
```



初始化hadoop文件格式（此图为网图，我自己的当时没截图）

```
hadoop namenode -format
```

![](https://s2.loli.net/2022/06/14/eBQ479iDRF3mWdo.png)

启动所有进程

```
start-all.sh
# 启动yarn
$HADOOP_HOME/sbin/start-yarn.sh
```

使用“ start-dfs.sh ”开启 NaneNode 和 DataNode 守护进程：

```
start-dfs.sh
```

![image-20220614150020371](https://s2.loli.net/2022/06/14/MbRr2vkqSYAGHaV.png)

```
#查看启动的进程
jps
```

![image-20220614150121542](https://s2.loli.net/2022/06/14/PqzkrI92BA8paHF.png)

成功启动后可以通过http://localhost:50070查看相关信息

<img src="https://s2.loli.net/2022/06/14/UD3x1IWt54fRH7G.png" alt="image-20220614155300167" style="zoom: 67%;" />



# kafka安装配置

新版本的kafka已经不需要单独安装zookeeper

[Index of /apache/kafka (cnnic.cn)](https://mirrors.cnnic.cn/apache/kafka/)

下载新版kafka并且解压

对config目录下的server.properties进行配置

```
vim config/server.properties
#配置如下
listeners=PLAINTEXT://localhost:9092
log.dirs=/home/zhuweihao/opt/kafka/logs
```

![image-20220614152428655](https://s2.loli.net/2022/06/14/CJoAKpkNih8PTsa.png)

以守护进程启动zookeeper

```
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```

接着启动kafka

```
bin/kafka-server-start.sh -daemon config/server.properties
```

![image-20220614152710606](https://s2.loli.net/2022/06/14/YGQ8eBHyWvERAUo.png)

QuorumPeerMain是zookeeper集群的启动类，用来加载配置启动QuorumPeer线程的



接下来可以对kafka进行测试

创建topic：

```
bin/kafka-topics.sh --create --topic test1 --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
```

查看topic

```
bin/kafka-topics.sh --list --bootstrap-server localhost:9092
```

删除topic

```
bin/kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic test1
```



```
bin/kafka-console-producer.sh --topic test1 --bootstrap-server localhost:9092
```

![image-20220614153447614](https://s2.loli.net/2022/06/14/5rPOBTdqGeC8mwv.png)

```
bin/kafka-console-consumer.sh --topic test1 --from-beginning --bootstrap-server localhost:9092
```

![image-20220614153647240](https://s2.loli.net/2022/06/14/xQL6ivXsElPRpn7.png)

![image-20220614153708541](https://s2.loli.net/2022/06/14/K53mSTlbMXB1IwA.png)





# Flink安装部署

前置工作如下：

关闭防火墙，关闭selinux，安装jdk，更改主机名，更改主机名与IP地址的映射关系，ssh免密码登录等

##### Flink Local模式部署

local模式不需要进行任何配置，只要保证jdk的正确安装就可以

```
#启动flink
start-cluster.sh
#启动后多了如下两个进程
17992 StandaloneSessionClusterEntrypoint
18264 TaskManagerRunner
```

![image-20220614154824774](https://s2.loli.net/2022/06/14/sQvqJuYl5mfbNEG.png)

可通过http://localhost:8081/#/overview查看相关信息

<img src="https://s2.loli.net/2022/06/14/XpnDVIKcqEJQLSv.png" alt="image-20220614155220145" style="zoom: 50%;" />

测试

```
bin/flink run examples/batch/WordCount.jar
```

<img src="https://s2.loli.net/2022/06/14/JW7UyrbdMsGX2RB.png" alt="image-20220614155958203" style="zoom:67%;" />

关闭flink

```
stop-cluster.sh
```

![image-20220614160232051](https://s2.loli.net/2022/06/14/h3L1AeIauwiXHt8.png)





